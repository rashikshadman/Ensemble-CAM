{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os, json\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#transforms\n",
    "#from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "#from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "    LayerCAM, FullGrad, GradCAMElementWise\n",
    ")\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image, deprocess_image, preprocess_image\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from flashtorch.utils import apply_transforms, load_image\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cda899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(cam, threshold):\n",
    "    return np.where(cam >= threshold, cam, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_cam(image_path):\n",
    "    rgb_img_original = cv2.imread(image_path, 1)[:, :, ::-1]\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "    face_model = \"models/facePADceleb_adamW_new.pt\"\n",
    "    model = torch.load(face_model)\n",
    "    model.to(device)\n",
    "    \n",
    "    rgb_img_pil = Image.fromarray(rgb_img_original)\n",
    "    img_t = get_input_tensors(rgb_img_pil)\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(img_t.cuda())\n",
    "    \n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    probs2 = probs.topk(2)\n",
    "    \n",
    "    target_class = probs2.indices[0, 0].item() \n",
    "\n",
    "    target_layers = [model.features.denseblock4.denselayer24.conv2]\n",
    "    targets = [ClassifierOutputTarget(target_class)]\n",
    "\n",
    "    cam1 = GradCAM(model=model, target_layers=target_layers)\n",
    "    grayscale_cam1 = cam1(input_tensor=img_t.cuda(), targets=targets)\n",
    "    grayscale_cam1 = grayscale_cam1[0, :]\n",
    "    \n",
    "    max_val1 = grayscale_cam1.max()\n",
    "    if max_val1 > 0:  # Avoid division by zero\n",
    "       grayscale_cam1_norm = grayscale_cam1 / max_val1\n",
    "    else:\n",
    "       grayscale_cam1_norm = grayscale_cam1  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam1_norm = grayscale_cam1 / grayscale_cam1.max()\n",
    "    \n",
    "    cam2 = HiResCAM(model=model, target_layers=target_layers)\n",
    "    grayscale_cam2 = cam2(input_tensor=img_t.cuda(), targets=targets)\n",
    "    grayscale_cam2 = grayscale_cam2[0, :]\n",
    "    \n",
    "    max_val2 = grayscale_cam2.max()\n",
    "    if max_val2 > 0:  # Avoid division by zero\n",
    "       grayscale_cam2_norm = grayscale_cam2 / max_val2\n",
    "    else:\n",
    "       grayscale_cam2_norm = grayscale_cam2  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam2_norm = grayscale_cam2 / grayscale_cam2.max()\n",
    "    \n",
    "    cam3 = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "    grayscale_cam3 = cam3(input_tensor=img_t.cuda(), targets=targets)\n",
    "    grayscale_cam3 = grayscale_cam3[0, :]\n",
    "    \n",
    "    max_val3 = grayscale_cam3.max()\n",
    "    if max_val3 > 0:  # Avoid division by zero\n",
    "       grayscale_cam3_norm = grayscale_cam3 / max_val3\n",
    "    else:\n",
    "       grayscale_cam3_norm = grayscale_cam3  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam3_norm = grayscale_cam3 / grayscale_cam3.max()\n",
    "\n",
    "    grayscale_cam = (grayscale_cam1_norm + grayscale_cam2_norm + grayscale_cam3_norm) / 3\n",
    "    \n",
    "\n",
    "  \n",
    "    threshold_1 = np.percentile(grayscale_cam, 90)\n",
    "\n",
    "    grayscale_cam_avg = apply_threshold(grayscale_cam, threshold_1)\n",
    "    \n",
    "    return rgb_img_original, device, model, target_class, img_t, grayscale_cam_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def apply_mask(image, heatmap, mask_type='black'):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Apply masking\n",
    "    perturbed_image = image.copy()\n",
    "    if mask_type == 'black':\n",
    "        perturbed_image[mask] = 0  # Set important regions to black\n",
    "    elif mask_type == 'mean':\n",
    "        mean_pixel_value = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "        perturbed_image[mask] = mean_pixel_value  # Set important regions to mean pixel value\n",
    "    elif mask_type == 'blur':\n",
    "        blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
    "        perturbed_image[mask] = blurred[mask]  # Apply blur to important regions\n",
    "    \n",
    "    pil_image = Image.fromarray(perturbed_image.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d11842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mask(mask, shift_y, shift_x):\n",
    "    \"\"\"\n",
    "    Shifts the mask by given offsets. Wraps around if necessary.\n",
    "    \n",
    "    Args:\n",
    "        mask: Input binary mask (2D array).\n",
    "        shift_y: Vertical shift (positive for down, negative for up).\n",
    "        shift_x: Horizontal shift (positive for right, negative for left).\n",
    "    \n",
    "    Returns:\n",
    "        Shifted mask of the same size.\n",
    "    \"\"\"\n",
    "    # Perform shift with wrapping using np.roll\n",
    "    shifted_mask = np.roll(mask, shift_y, axis=0)  # Shift vertically\n",
    "    shifted_mask = np.roll(shifted_mask, shift_x, axis=1)  # Shift horizontally\n",
    "    return shifted_mask\n",
    "\n",
    "def apply_mask_random(image, heatmap, mask_type='black'):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    # Generate random shifts\n",
    "    np.random.seed(42)\n",
    "    #shift_y = np.random.randint(-mask.shape[0] // 2, mask.shape[0] // 2)\n",
    "    #shift_x = np.random.randint(-mask.shape[1] // 2, mask.shape[1] // 2)\n",
    "    \n",
    "    shift_y = np.random.randint(-image.shape[0], image.shape[0])\n",
    "    shift_x = np.random.randint(-image.shape[1], image.shape[1])\n",
    "    \n",
    "    #print(\"Vertical:\", shift_y)\n",
    "    #print(\"Horizontal:\", shift_x)\n",
    "\n",
    "    # Shift the mask\n",
    "    shifted_mask = shift_mask(mask, shift_y, shift_x)\n",
    "    \n",
    "    # Apply masking\n",
    "    perturbed_image = image.copy()\n",
    "    if mask_type == 'black':\n",
    "        perturbed_image[shifted_mask] = 0  # Set important regions to black\n",
    "    elif mask_type == 'mean':\n",
    "        mean_pixel_value = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "        perturbed_image[mask] = mean_pixel_value  # Set important regions to mean pixel value\n",
    "    elif mask_type == 'blur':\n",
    "        blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
    "        perturbed_image[mask] = blurred[mask]  # Apply blur to important regions\n",
    "    \n",
    "    pil_image = Image.fromarray(perturbed_image.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confidence_drop(model, device, original_image, perturbed_image, target_class):\n",
    "    \"\"\"\n",
    "    Measure the drop in confidence between the original and perturbed image.\n",
    "    Arguments:\n",
    "    - model: Trained model\n",
    "    - original_image: Original input image (tensor)\n",
    "    - perturbed_image: Image with masked important regions (tensor)\n",
    "    - target_class: Target class for the prediction\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Original confidence\n",
    "    original_output = model(original_image.cuda())\n",
    "    original_confidence = F.softmax(original_output, dim=1)[0, target_class].item()\n",
    "\n",
    "    # Perturbed confidence\n",
    "    perturbed_output = model(perturbed_image.cuda())\n",
    "    perturbed_confidence = F.softmax(perturbed_output, dim=1)[0, target_class].item()\n",
    "\n",
    "    # Calculate confidence drop\n",
    "    confidence_drop = original_confidence - perturbed_confidence\n",
    "    return confidence_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluate(image_path):\n",
    "    \n",
    " \n",
    "  img, device, model, target_class, img_t, cam = ensemble_cam(image_path)\n",
    " \n",
    "    \n",
    "  perturbed_image = apply_mask(img, cam)\n",
    "\n",
    "  perturbed_image_t = get_input_tensors(perturbed_image)\n",
    "    \n",
    "  random_image = apply_mask_random(img, cam)\n",
    "\n",
    "  random_image_t = get_input_tensors(random_image)\n",
    "\n",
    "    \n",
    "  \n",
    "   \n",
    "  ensemble_confidence_drop = evaluate_confidence_drop(model, device, img_t, perturbed_image_t, target_class)\n",
    "   \n",
    "  random_confidence_drop = evaluate_confidence_drop(model, device, img_t, random_image_t, target_class)\n",
    "  \n",
    "\n",
    "  return ensemble_confidence_drop, random_confidence_drop\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb98507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder containing subfolders of images\n",
    "root_folder = \"Celeba_spoof/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_folder_one(folder_path):\n",
    "    \"\"\"\n",
    "    Process all images in a folder and its subfolders, calculate average confidence drops.\n",
    "    \"\"\"\n",
    "    ensemble_confidence_drop_avg = []\n",
    "    random_confidence_drop_avg = []\n",
    "  \n",
    "    \n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "       for file in files:  # Loop through each file in the current directory\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            drop_case1, drop_case2 = ensemble_evaluate(image_path)\n",
    "            ensemble_confidence_drop_avg.append(drop_case1)\n",
    "            random_confidence_drop_avg.append(drop_case2)\n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    avg_drop_ensemble = np.mean(ensemble_confidence_drop_avg)\n",
    "    avg_drop_random = np.mean(random_confidence_drop_avg)\n",
    "\n",
    "    return avg_drop_ensemble, avg_drop_random\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "# Process the folder and calculate average confidence drops\n",
    "avg_case1, avg_case2 = process_folder_one(root_folder)\n",
    "\n",
    "print(f\"Average Confidence Drop (Ensemble): {avg_case1}\")\n",
    "print(f\"Average Confidence Drop (random): {avg_case2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_mask(image, heatmap):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    # Convert to NumPy array\n",
    "    #image = np.array(image)\n",
    "\n",
    "    # Resize heatmap to match the image size\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create a binary mask\n",
    "    mask = heatmap > threshold\n",
    "\n",
    "    # Ensure the image is a proper copy\n",
    "    perturbed_image = np.copy(image)\n",
    "\n",
    "    # Initialize the result image with black\n",
    "    result = np.zeros_like(perturbed_image)\n",
    "\n",
    "  \n",
    "\n",
    "    # Copy the mask region to the result\n",
    "    result[mask] = perturbed_image[mask]\n",
    "    \n",
    "    \n",
    "    pil_image = Image.fromarray(result.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_mask_random(image, heatmap):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    # Convert the PIL image to a numpy array\n",
    "    #image = np.array(image)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    # Generate random shifts\n",
    "    np.random.seed(42)\n",
    "    #shift_y = np.random.randint(-mask.shape[0] // 2, mask.shape[0] // 2)\n",
    "    #shift_x = np.random.randint(-mask.shape[1] // 2, mask.shape[1] // 2)\n",
    "    \n",
    "    shift_y = np.random.randint(-image.shape[0], image.shape[0])\n",
    "    shift_x = np.random.randint(-image.shape[1], image.shape[1])\n",
    "    \n",
    "\n",
    "    # Shift the mask\n",
    "    shifted_mask = shift_mask(mask, shift_y, shift_x)\n",
    "    \n",
    "     # Ensure the image is a proper copy\n",
    "    perturbed_image = np.copy(image)\n",
    "\n",
    "    # Initialize the result image with black\n",
    "    result = np.zeros_like(perturbed_image)\n",
    "\n",
    "  \n",
    "\n",
    "    # Copy the mask region to the result\n",
    "    result[shifted_mask] = perturbed_image[shifted_mask]\n",
    "    \n",
    "    \n",
    "    pil_image = Image.fromarray(result.astype('uint8'))\n",
    "    return pil_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24a2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_mask_evaluate(image_path):\n",
    "    \n",
    " \n",
    "  img, device, model, target_class, img_t, cam = ensemble_cam(image_path)\n",
    " \n",
    "    \n",
    "  perturbed_image = only_mask(img, cam)\n",
    "\n",
    "  perturbed_image_t = get_input_tensors(perturbed_image)\n",
    "    \n",
    "  random_image = only_mask_random(img, cam)\n",
    "\n",
    "  random_image_t = get_input_tensors(random_image)\n",
    "\n",
    "    \n",
    "  \n",
    "   \n",
    "  ensemble_confidence_drop = evaluate_confidence_drop(model, device, img_t, perturbed_image_t, target_class)\n",
    "   \n",
    "  random_confidence_drop = evaluate_confidence_drop(model, device, img_t, random_image_t, target_class)\n",
    "  \n",
    "\n",
    "  return ensemble_confidence_drop, random_confidence_drop\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder_mask(folder_path):\n",
    "    \"\"\"\n",
    "    Process all images in a folder and its subfolders, calculate average confidence drops.\n",
    "    \"\"\"\n",
    "    ensemble_confidence_drop_avg = []\n",
    "    random_confidence_drop_avg = []\n",
    "  \n",
    "    \n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "       for file in files:  # Loop through each file in the current directory\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            drop_case1, drop_case2 = ensemble_mask_evaluate(image_path)\n",
    "            ensemble_confidence_drop_avg.append(drop_case1)\n",
    "            random_confidence_drop_avg.append(drop_case2)\n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    avg_drop_ensemble = np.mean(ensemble_confidence_drop_avg)\n",
    "    avg_drop_random = np.mean(random_confidence_drop_avg)\n",
    "\n",
    "    return avg_drop_ensemble, avg_drop_random\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "# Process the folder and calculate average confidence drops\n",
    "avg_case1, avg_case2 = process_folder_mask(root_folder)\n",
    "\n",
    "print(f\"Average Confidence Drop (Ensemble): {avg_case1}\")\n",
    "print(f\"Average Confidence Drop (random): {avg_case2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00411788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, original_image, perturbed_image, random_perturbed_image):\n",
    "\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  # Original confidence\n",
    "  original_output = model(original_image.cuda())\n",
    "  original_probs = F.softmax(original_output, dim=1)\n",
    "  original_top_prob, original_top_class = torch.max(original_probs, dim=1)\n",
    "  original_top_prob = original_top_prob.item()\n",
    "  original_top_class = original_top_class.item()\n",
    "\n",
    "\n",
    "\n",
    "  # Perturbed confidence\n",
    "  perturbed_output = model(perturbed_image.cuda())\n",
    "  perturbed_probs = F.softmax(perturbed_output, dim=1)\n",
    "  perturbed_top_prob, perturbed_top_class = torch.max(perturbed_probs, dim=1)\n",
    "  perturbed_top_prob = perturbed_top_prob.item()\n",
    "  perturbed_top_class = perturbed_top_class.item()\n",
    "  \n",
    "  perturbed_confidence = F.softmax(perturbed_output, dim=1)[0, original_top_class].item()\n",
    "\n",
    "  \n",
    "  # random Perturbed confidence\n",
    "  random_perturbed_output = model(random_perturbed_image.cuda())\n",
    "  random_perturbed_probs = F.softmax(random_perturbed_output, dim=1)\n",
    "  random_perturbed_top_prob, random_perturbed_top_class = torch.max(random_perturbed_probs, dim=1)\n",
    "  random_perturbed_top_prob = random_perturbed_top_prob.item()\n",
    "  random_perturbed_top_class = random_perturbed_top_class.item()\n",
    "  \n",
    "  random_perturbed_confidence = F.softmax(random_perturbed_output, dim=1)[0, original_top_class].item()\n",
    "\n",
    "  return original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_data(image_path):\n",
    "  \n",
    "  img, device, model, target_class, img_t, cam = ensemble_cam(image_path)\n",
    " \n",
    "    \n",
    "  perturbed_image = apply_mask(img, cam)\n",
    "\n",
    "  perturbed_image_t = get_input_tensors(perturbed_image)\n",
    "    \n",
    "  random_image = apply_mask_random(img, cam)\n",
    "\n",
    "  random_image_t = get_input_tensors(random_image)\n",
    "\n",
    "    \n",
    "  #target_class = probs5.indices[0, 0].item() \n",
    "   \n",
    "  #SDD_confidence_drop = evaluate_confidence_drop(model, img_t, perturbed_image_t, target_class)\n",
    "   \n",
    "  #random_confidence_drop = evaluate_confidence_drop(model, img_t, random_image_t, target_class)\n",
    "  original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence = evaluate(model, device, img_t, perturbed_image_t, random_image_t) \n",
    "  \n",
    "  return  original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ff24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_mask_data(image_path):\n",
    "  \n",
    "  img, device, model, target_class, img_t, cam = ensemble_cam(image_path)\n",
    " \n",
    "    \n",
    "  perturbed_image = only_mask(img, cam)\n",
    "\n",
    "  perturbed_image_t = get_input_tensors(perturbed_image)\n",
    "    \n",
    "  random_image = only_mask_random(img, cam)\n",
    "\n",
    "  random_image_t = get_input_tensors(random_image)\n",
    "\n",
    "    \n",
    "  #target_class = probs5.indices[0, 0].item() \n",
    "   \n",
    "  #SDD_confidence_drop = evaluate_confidence_drop(model, img_t, perturbed_image_t, target_class)\n",
    "   \n",
    "  #random_confidence_drop = evaluate_confidence_drop(model, img_t, random_image_t, target_class)\n",
    "  original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence = evaluate(model, device, img_t, perturbed_image_t, random_image_t) \n",
    "  \n",
    "  return  original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639737e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def process_folder_two(folder_path):\n",
    "    \"\"\"\n",
    "    Process all images in a folder and its subfolders, calculate average confidence drops.\n",
    "    \"\"\"\n",
    "    #sdd_confidence_drop_avg = []\n",
    "    #random_confidence_drop_avg = []\n",
    "    image_name = []\n",
    "    original_top_class_all = []\n",
    "    original_top_prob_all = []\n",
    "    perturbed_top_class_all = []\n",
    "    perturbed_top_prob_all = []\n",
    "    perturbed_confidence_all = []\n",
    "    random_perturbed_top_class_all = []\n",
    "    random_perturbed_top_prob_all = []\n",
    "    random_perturbed_confidence_all = []\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "       for file in files:  # Loop through each file in the current directory\n",
    "            image_name.append(file)\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            #drop_case1, drop_case2 = sdd_generate(image_path)\n",
    "            #sdd_confidence_drop_avg.append(drop_case1)\n",
    "            #random_confidence_drop_avg.append(drop_case2)\n",
    "            original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence = ensemble_data(image_path) \n",
    "            original_top_class_all.append(original_top_class)\n",
    "            original_top_prob_all.append(original_top_prob)\n",
    "            perturbed_top_class_all.append(perturbed_top_class)\n",
    "            perturbed_top_prob_all.append(perturbed_top_prob)\n",
    "            perturbed_confidence_all.append(perturbed_confidence)\n",
    "            random_perturbed_top_class_all.append(random_perturbed_top_class)\n",
    "            random_perturbed_top_prob_all.append(random_perturbed_top_prob)\n",
    "            random_perturbed_confidence_all.append(random_perturbed_confidence)\n",
    "            \n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "    # Combine lists into a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "           'Image': image_name,\n",
    "           'Original_Prediction': original_top_class_all,\n",
    "           'Original_Prob': original_top_prob_all,\n",
    "           'Ensemble_Pertb_Prediction': perturbed_top_class_all,\n",
    "           'Ensemble_Pertb_Prob': perturbed_top_prob_all,\n",
    "           'Ensemble_Pertb_Prob_Original_Pred': perturbed_confidence_all,\n",
    "           'Random_Pertb_Prediction': random_perturbed_top_class_all,\n",
    "           'Random_Pertb_Prob': random_perturbed_top_prob_all,\n",
    "           'Random_Pertb_Prob_Original_Pred': random_perturbed_confidence_all\n",
    "                         })\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = process_folder_two(root_folder)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder_mask_two(folder_path):\n",
    "    \"\"\"\n",
    "    Process all images in a folder and its subfolders, calculate average confidence drops.\n",
    "    \"\"\"\n",
    "    #sdd_confidence_drop_avg = []\n",
    "    #random_confidence_drop_avg = []\n",
    "    image_name = []\n",
    "    original_top_class_all = []\n",
    "    original_top_prob_all = []\n",
    "    perturbed_top_class_all = []\n",
    "    perturbed_top_prob_all = []\n",
    "    perturbed_confidence_all = []\n",
    "    random_perturbed_top_class_all = []\n",
    "    random_perturbed_top_prob_all = []\n",
    "    random_perturbed_confidence_all = []\n",
    "\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "       for file in files:  # Loop through each file in the current directory\n",
    "            image_name.append(file)\n",
    "            image_path = os.path.join(subdir, file)\n",
    "            #drop_case1, drop_case2 = sdd_generate(image_path)\n",
    "            #sdd_confidence_drop_avg.append(drop_case1)\n",
    "            #random_confidence_drop_avg.append(drop_case2)\n",
    "            original_top_class, original_top_prob, perturbed_top_class, perturbed_top_prob, perturbed_confidence, random_perturbed_top_class, random_perturbed_top_prob, random_perturbed_confidence = ensemble_mask_data(image_path) \n",
    "            original_top_class_all.append(original_top_class)\n",
    "            original_top_prob_all.append(original_top_prob)\n",
    "            perturbed_top_class_all.append(perturbed_top_class)\n",
    "            perturbed_top_prob_all.append(perturbed_top_prob)\n",
    "            perturbed_confidence_all.append(perturbed_confidence)\n",
    "            random_perturbed_top_class_all.append(random_perturbed_top_class)\n",
    "            random_perturbed_top_prob_all.append(random_perturbed_top_prob)\n",
    "            random_perturbed_confidence_all.append(random_perturbed_confidence)\n",
    "            \n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "    # Combine lists into a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "           'Image': image_name,\n",
    "           'Original_Prediction': original_top_class_all,\n",
    "           'Original_Prob': original_top_prob_all,\n",
    "           'Ensemble_Pertb_Prediction': perturbed_top_class_all,\n",
    "           'Ensemble_Pertb_Prob': perturbed_top_prob_all,\n",
    "           'Ensemble_Pertb_Prob_Original_Pred': perturbed_confidence_all,\n",
    "           'Random_Pertb_Prediction': random_perturbed_top_class_all,\n",
    "           'Random_Pertb_Prob': random_perturbed_top_prob_all,\n",
    "           'Random_Pertb_Prob_Original_Pred': random_perturbed_confidence_all\n",
    "                         })\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df_2 = process_folder_mask_two(root_folder)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9718951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of differences\n",
    "num_differences_1 = (df_2['Original_Prediction'] != df_2['Ensemble_Pertb_Prediction']).sum()\n",
    "\n",
    "# Calculate the percentage of differences\n",
    "percentage_differences_1 = (num_differences_1 / len(df_2['Original_Prediction'])) * 100\n",
    "\n",
    "print(f\"Percentage of differences for Ensemble: {percentage_differences_1:.2f}%\")\n",
    "\n",
    "\n",
    "# Count the number of differences\n",
    "num_differences_2 = (df_2['Original_Prediction'] != df_2['Random_Pertb_Prediction']).sum()\n",
    "\n",
    "# Calculate the percentage of differences\n",
    "percentage_differences_2 = (num_differences_2 / len(df_2['Original_Prediction'])) * 100\n",
    "\n",
    "print(f\"Percentage of differences for Random: {percentage_differences_2:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd373715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract Column2 from Column1\n",
    "difference_1 = df_2['Original_Prob'] - df_2['Ensemble_Pertb_Prob_Original_Pred']\n",
    "difference_2 = df_2['Original_Prob'] - df_2['Random_Pertb_Prob_Original_Pred']\n",
    "\n",
    "# Calculate the average of the difference\n",
    "average_difference_1 = difference_1.mean()\n",
    "average_difference_2 = difference_2.mean()\n",
    "\n",
    "print(\"Ensemble Confidence Drop:\", average_difference_1)\n",
    "print(\"Random Confidence Drop:\", average_difference_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# List of column names and titles\n",
    "columns = ['Original_Prob', 'Ensemble_Pertb_Prob_Original_Pred'] #'Random_Pertb_Prob_Original_Pred']\n",
    "titles = ['Original Probability', 'Ensemble_CAM Retention Prob Original Pred'] #'Random Retention Prob Original Pred']\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    # Compute mean and standard deviation\n",
    "    mean, std = df_2[col].mean(), df_2[col].std()\n",
    "\n",
    "    # Generate x values for the bell curve\n",
    "    x = np.linspace(df_2[col].min(), df_2[col].max(), 100)\n",
    "    y = stats.norm.pdf(x, mean, std)\n",
    "\n",
    "    # Plot bell curve\n",
    "    axes[i].plot(x, y, 'r-', lw=2)\n",
    "    \n",
    "\n",
    "    # Set labels\n",
    "    axes[i].set_title(titles[i])\n",
    "    axes[i].set_xlabel('Probability')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    \n",
    "    # Ensure y-axis scale goes up to 6\n",
    "    axes[i].set_ylim(0, 6)  # Keeps the upper limit at 6\n",
    "    axes[i].set_yticks(np.arange(0, 6.2, 0.4))  # Ticks from 0 to 6 with a step of 0.2\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09945664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
