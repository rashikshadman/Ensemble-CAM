{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os, json\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#transforms\n",
    "#from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "#from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "    LayerCAM, FullGrad, GradCAMElementWise\n",
    ")\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image, deprocess_image, preprocess_image\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from flashtorch.utils import apply_transforms, load_image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Celeba_spoof/test/fake/494514.png\"\n",
    "#image_path = \"meeting_3/correct_prediction/4/494684.png\"\n",
    "rgb_img_original = cv2.imread(image_path, 1)[:, :, ::-1]\n",
    "plt.imshow(rgb_img_original)\n",
    "rgb_img = np.float32(rgb_img_original) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9413311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e583f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "face_model = \"models/facePADceleb_adamW_new.pt\"\n",
    "model = torch.load(face_model)\n",
    "#print(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img_pil = Image.fromarray(rgb_img_original)\n",
    "img_t = get_input_tensors(rgb_img_pil)\n",
    "#img_t = img_t.cuda()\n",
    "#print(img_t.device)\n",
    "model.eval()\n",
    "\n",
    "logits = model(img_t.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadc0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(logits, dim=1)\n",
    "probs2 = probs.topk(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03efbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(cam, threshold):\n",
    "    return np.where(cam >= threshold, cam, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37321060",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = probs2.indices[0, 0].item() \n",
    "\n",
    "target_layers = [model.features.denseblock4.denselayer24.conv2]\n",
    "targets = [ClassifierOutputTarget(target_class)]\n",
    "\n",
    "cam1 = GradCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam1 = cam1(input_tensor=img_t.cuda(), targets=targets)\n",
    "grayscale_cam1 = grayscale_cam1[0, :]\n",
    "\n",
    "print(\"cam1\", grayscale_cam1)\n",
    "print(grayscale_cam1.shape)\n",
    "\n",
    "min_val1 = grayscale_cam1.min()    \n",
    "max_val1 = grayscale_cam1.max()\n",
    "print(\"max_gradcam:\", max_val1)\n",
    "print(\"min_gradcam:\", min_val1)\n",
    "if max_val1 > 0:  # Avoid division by zero\n",
    "    grayscale_cam1_norm = grayscale_cam1 / max_val1\n",
    "else:\n",
    "    grayscale_cam1_norm = grayscale_cam1  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam1_norm = grayscale_cam1 / grayscale_cam1.max()\n",
    "    \n",
    "cam2 = HiResCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam2 = cam2(input_tensor=img_t.cuda(), targets=targets)\n",
    "grayscale_cam2 = grayscale_cam2[0, :]\n",
    "\n",
    "print(\"cam2\", grayscale_cam2)\n",
    "print(grayscale_cam2.shape)\n",
    "    \n",
    "min_val2 = grayscale_cam2.min()\n",
    "max_val2 = grayscale_cam2.max()\n",
    "print(\"max_hires:\", max_val2)\n",
    "print(\"min_hires:\", min_val2)\n",
    "if max_val2 > 0:  # Avoid division by zero\n",
    "    grayscale_cam2_norm = grayscale_cam2 / max_val2\n",
    "else:\n",
    "    grayscale_cam2_norm = grayscale_cam2  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam2_norm = grayscale_cam2 / grayscale_cam2.max()\n",
    "    \n",
    "cam3 = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "grayscale_cam3 = cam3(input_tensor=img_t.cuda(), targets=targets)\n",
    "grayscale_cam3 = grayscale_cam3[0, :]\n",
    "    \n",
    "print(\"cam3\", grayscale_cam3) \n",
    "print(grayscale_cam3.shape)\n",
    "\n",
    "min_val3 = grayscale_cam3.min() \n",
    "max_val3 = grayscale_cam3.max()\n",
    "print(\"max_++:\", max_val3)\n",
    "print(\"min_++:\", min_val3)\n",
    "if max_val3 > 0:  # Avoid division by zero\n",
    "    grayscale_cam3_norm = grayscale_cam3 / max_val3\n",
    "else:\n",
    "    grayscale_cam3_norm = grayscale_cam3  # Keep it unchanged if max is zero\n",
    "    #grayscale_cam3_norm = grayscale_cam3 / grayscale_cam3.max()\n",
    "\n",
    "grayscale_cam = (grayscale_cam1_norm + grayscale_cam2_norm + grayscale_cam3_norm) / 3\n",
    "    \n",
    "print(\"cam\",grayscale_cam)\n",
    "  \n",
    "threshold_1 = np.percentile(grayscale_cam, 90)\n",
    "print(\"threshold\", threshold_1)\n",
    "\n",
    "grayscale_cam_avg = apply_threshold(grayscale_cam, threshold_1)\n",
    "print(grayscale_cam_avg.shape)\n",
    "\n",
    "grayscale_cams = [grayscale_cam_avg, grayscale_cam1, grayscale_cam2, grayscale_cam3]\n",
    "\n",
    "for i, grayscale_cam in enumerate(grayscale_cams):\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    cam_image = cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cam_output_path = os.path.join('output/cams', f'cam_{i+1}.jpg')\n",
    "    cv2.imwrite(cam_output_path, cam_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def apply_mask(image, heatmap, mask_type='black'):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    print(\"threshold\", threshold)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Apply masking\n",
    "    perturbed_image = image.copy()\n",
    "    if mask_type == 'black':\n",
    "        perturbed_image[mask] = 0  # Set important regions to black\n",
    "    elif mask_type == 'mean':\n",
    "        mean_pixel_value = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "        perturbed_image[mask] = mean_pixel_value  # Set important regions to mean pixel value\n",
    "    elif mask_type == 'blur':\n",
    "        blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
    "        perturbed_image[mask] = blurred[mask]  # Apply blur to important regions\n",
    "    \n",
    "    pil_image = Image.fromarray(perturbed_image.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951de384",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_image = apply_mask(rgb_img_original, grayscale_cam_avg)\n",
    "\n",
    "plt.imshow(perturbed_image)\n",
    "\n",
    "\n",
    "\n",
    "perturbed_image_t = get_input_tensors(perturbed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mask(mask, shift_y, shift_x):\n",
    "    \"\"\"\n",
    "    Shifts the mask by given offsets. Wraps around if necessary.\n",
    "    \n",
    "    Args:\n",
    "        mask: Input binary mask (2D array).\n",
    "        shift_y: Vertical shift (positive for down, negative for up).\n",
    "        shift_x: Horizontal shift (positive for right, negative for left).\n",
    "    \n",
    "    Returns:\n",
    "        Shifted mask of the same size.\n",
    "    \"\"\"\n",
    "    # Perform shift with wrapping using np.roll\n",
    "    shifted_mask = np.roll(mask, shift_y, axis=0)  # Shift vertically\n",
    "    shifted_mask = np.roll(shifted_mask, shift_x, axis=1)  # Shift horizontally\n",
    "    return shifted_mask\n",
    "\n",
    "def apply_mask_random(image, heatmap, mask_type='black'):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold=np.percentile(heatmap, 0)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    # Generate random shifts\n",
    "    np.random.seed(42)\n",
    "    #shift_y = np.random.randint(-mask.shape[0] // 2, mask.shape[0] // 2)\n",
    "    #shift_x = np.random.randint(-mask.shape[1] // 2, mask.shape[1] // 2)\n",
    "    \n",
    "    shift_y = np.random.randint(-image.shape[0], image.shape[0])\n",
    "    shift_x = np.random.randint(-image.shape[1], image.shape[1])\n",
    "    \n",
    "    print(\"Vertical:\", shift_y)\n",
    "    print(\"Horizontal:\", shift_x)\n",
    "\n",
    "    # Shift the mask\n",
    "    shifted_mask = shift_mask(mask, shift_y, shift_x)\n",
    "    \n",
    "    # Apply masking\n",
    "    perturbed_image = image.copy()\n",
    "    if mask_type == 'black':\n",
    "        perturbed_image[shifted_mask] = 0  # Set important regions to black\n",
    "    elif mask_type == 'mean':\n",
    "        mean_pixel_value = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "        perturbed_image[mask] = mean_pixel_value  # Set important regions to mean pixel value\n",
    "    elif mask_type == 'blur':\n",
    "        blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
    "        perturbed_image[mask] = blurred[mask]  # Apply blur to important regions\n",
    "    \n",
    "    pil_image = Image.fromarray(perturbed_image.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = apply_mask_random(rgb_img_original, grayscale_cam_avg)\n",
    "plt.imshow(random_image)\n",
    "\n",
    "random_image_t = get_input_tensors(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = probs2.indices[0, 0].item() \n",
    "print(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3077d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confidence_drop(model, device, original_image, perturbed_image, target_class):\n",
    "    \"\"\"\n",
    "    Measure the drop in confidence between the original and perturbed image.\n",
    "    Arguments:\n",
    "    - model: Trained model\n",
    "    - original_image: Original input image (tensor)\n",
    "    - perturbed_image: Image with masked important regions (tensor)\n",
    "    - target_class: Target class for the prediction\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Original confidence\n",
    "    original_output = model(original_image.cuda())\n",
    "    original_confidence = torch.softmax(original_output, dim=1)[0, target_class].item()\n",
    "\n",
    "    # Perturbed confidence\n",
    "    perturbed_output = model(perturbed_image.cuda())\n",
    "    perturbed_confidence = torch.softmax(perturbed_output, dim=1)[0, target_class].item()\n",
    "\n",
    "    # Calculate confidence drop\n",
    "    confidence_drop = original_confidence - perturbed_confidence\n",
    "    return confidence_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ee99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_confidence_drop = evaluate_confidence_drop(model, device, img_t, perturbed_image_t, target_class)\n",
    "print(Ensemble_confidence_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_confidence_drop = evaluate_confidence_drop(model, device, img_t, random_image_t, target_class)\n",
    "print(random_confidence_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c981bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_mask(image, heatmap):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    # Convert to NumPy array\n",
    "    #image = np.array(image)\n",
    "\n",
    "    # Resize heatmap to match the image size\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create a binary mask\n",
    "    mask = heatmap > threshold\n",
    "\n",
    "    # Ensure the image is a proper copy\n",
    "    perturbed_image = np.copy(image)\n",
    "\n",
    "    # Initialize the result image with black\n",
    "    result = np.zeros_like(perturbed_image)\n",
    "\n",
    "  \n",
    "\n",
    "    # Copy the mask region to the result\n",
    "    result[mask] = perturbed_image[mask]\n",
    "    \n",
    "    \n",
    "    pil_image = Image.fromarray(result.astype('uint8'))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74eaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_mask_random(image, heatmap):\n",
    "    \"\"\"\n",
    "    Mask the image based on the Grad-CAM heatmap.\n",
    "    Arguments:\n",
    "    - image: Original input image (numpy array)\n",
    "    - heatmap: Grad-CAM heatmap (numpy array)\n",
    "    - mask_type: Type of masking ('black', 'blur', or 'mean')\n",
    "    \"\"\"\n",
    "     \n",
    "    threshold = np.percentile(heatmap, 0)\n",
    "    # Convert the PIL image to a numpy array\n",
    "    #image = np.array(image)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))  # Resize heatmap to image size\n",
    "    mask = heatmap > threshold  # Create a binary mask of important regions\n",
    "    \n",
    "    # Generate random shifts\n",
    "    np.random.seed(42)\n",
    "    #shift_y = np.random.randint(-mask.shape[0] // 2, mask.shape[0] // 2)\n",
    "    #shift_x = np.random.randint(-mask.shape[1] // 2, mask.shape[1] // 2)\n",
    "    \n",
    "    shift_y = np.random.randint(-image.shape[0], image.shape[0])\n",
    "    shift_x = np.random.randint(-image.shape[1], image.shape[1])\n",
    "    \n",
    "\n",
    "    # Shift the mask\n",
    "    shifted_mask = shift_mask(mask, shift_y, shift_x)\n",
    "    \n",
    "     # Ensure the image is a proper copy\n",
    "    perturbed_image = np.copy(image)\n",
    "\n",
    "    # Initialize the result image with black\n",
    "    result = np.zeros_like(perturbed_image)\n",
    "\n",
    "  \n",
    "\n",
    "    # Copy the mask region to the result\n",
    "    result[shifted_mask] = perturbed_image[shifted_mask]\n",
    "    \n",
    "    \n",
    "    pil_image = Image.fromarray(result.astype('uint8'))\n",
    "    return pil_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a72a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = only_mask(rgb_img_original, grayscale_cam_avg)\n",
    "\n",
    "plt.imshow(mask_image)\n",
    "\n",
    "\n",
    "\n",
    "mask_image_t = get_input_tensors(mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mask_image = only_mask_random(rgb_img_original, grayscale_cam_avg)\n",
    "plt.imshow(random_mask_image)\n",
    "\n",
    "random_mask_image_t = get_input_tensors(random_mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e486fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_mask_confidence_drop = evaluate_confidence_drop(model, device, img_t, mask_image_t, target_class)\n",
    "print(Ensemble_mask_confidence_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36211869",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_mask_confidence_drop = evaluate_confidence_drop(model, device, img_t, random_mask_image_t, target_class)\n",
    "print(random_mask_confidence_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f64b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
